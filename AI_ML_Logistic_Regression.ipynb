{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI/ML Logistic Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgfLrEh8jELI",
        "colab_type": "text"
      },
      "source": [
        "Setup/import steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04SjF3fIemCc",
        "colab_type": "code",
        "outputId": "db4468a8-eaaf-4d54-be5b-f82148734390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import json\n",
        "import os\n",
        "#To mount the drive from where files can be read\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n82HqgnirFf",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing and loading the data which will be used for training the model in the expected format (features list and labels list):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvPTku1Ag0dy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reading the dataset and loading the data as required\n",
        "f = open(\"/content/drive/My Drive/AI ML Group/lr_dataset.json\",\"r\")\n",
        "res = json.load(f)\n",
        "items = res['data']\n",
        "#print (len(items))\n",
        "titles = list()\n",
        "categories = list()\n",
        "for item in items:\n",
        "  titles.append(item['title'])\n",
        "  categories.append(item['comprehensive_category'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiIoGf9Hg8Io",
        "colab_type": "code",
        "outputId": "12012e50-75cb-483a-e89d-19025b73051c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#print the first 5 title and categories..just to check  \n",
        "print (titles[:5])  \n",
        "print (categories[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Women's Caftan Dress - Xhilaration&#153; (Juniors') Jade L\", \"Women's Plus Size Denim Jacket  - Universal Thread&#153; White Wash X\", \"Vegas Golden Knights Women's Short Sleeve Heathered T-Shirt - L\", \"Girls' Rockergirl Studded Ballets - Stevies Black 1\", '1/3 CT. T.W. Simulated Sapphire Trio Circle Necklace in Sterling Silver - Sapphire']\n",
            "['dresses', 'jackets', 't-shirts', 'shoes', 'necklaces']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqG6LaAMjLsx",
        "colab_type": "text"
      },
      "source": [
        "Actual application logic begins here.\n",
        "The loaded data is split into train and test samples. The 'train' samples will be used to train the model, and the 'test' samples will be used to evaluate the accuracy of the model on data which it has not seen before.\n",
        "The test size is taken as 25% of the available data, with a specific random seed so that the actual data split remains the same across different runs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2KqVC6lhNIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(titles, categories, test_size=0.25, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU_ZhnPOhVon",
        "colab_type": "code",
        "outputId": "d181943d-2d59-4cc0-afc6-a17c77fef5f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print (len(x_train))\n",
        "print (len(y_train))\n",
        "print (len(x_test))\n",
        "print (len(y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24297\n",
            "24297\n",
            "8099\n",
            "8099\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bpm4vK74jz4W",
        "colab_type": "text"
      },
      "source": [
        "Our feature data (titles) are still in string form, and we need them to be numeric values so that a model can be trained. The CountVectorizer uses a simple count of terms in order to compute vector representations of the strings. We set binary=True to facilitate one-vs-rest scheme.\n",
        "We also configure the vectorizer to use word-ngrams with up to 2 words. Any word occurring in over 90% of the documents is dropped (max_df is the max document frequency allowed).\n",
        "We strip accents from the string to allow only the ascii character set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk8Urqmmh5ja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "cv = CountVectorizer(strip_accents='ascii', analyzer='word', ngram_range=(1,2), max_df=0.9, binary=True)\n",
        "cv.fit_transform(x_train)\n",
        "\n",
        "train_feature_set=cv.transform(x_train) #transforming titles to vectors for train set\n",
        "test_feature_set=cv.transform(x_test) #transforming titles to vectors for test set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR1vsWEsnFoY",
        "colab_type": "text"
      },
      "source": [
        "We then instantiate a LogisticRegression object which will be used to create our model. The 'balanced' class_weight handles class imbalances in the number of training samples for each class. The BFGS algorithm is used since the dataset is small. The 'multinomial' class specifies that the data has multiple classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU-ZirTeiG0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generating the model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logisticRegr = LogisticRegression(class_weight='balanced', solver='lbfgs', multi_class='ovr', max_iter=1000)\n",
        "\n",
        "model = logisticRegr.fit(train_feature_set, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qyw1aB6KzIDJ",
        "colab_type": "text"
      },
      "source": [
        "We can then pass the test samples, which the model has not seen before, to predict the labels for these samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FViXhc9miT6y",
        "colab_type": "code",
        "outputId": "e2addbe6-e514-4971-caf1-ed8e6a96b851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#testing the model\n",
        "predictions = model.predict(test_feature_set[:3])\n",
        "result = (dict(zip(x_test[:3], predictions)))\n",
        "for key in result:\n",
        "  print (\"%s: %s\" % (key, result[key]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Women's Plus Faux Fur Jacket - Ava & Viv&#153; Burgundy 2X: jackets\n",
            "Women's Stranger Things&#174; Character Walking Raglan 3/4 Sleeve T-Shirt (Juniors') - Gray/Red L: t-shirts\n",
            "18k Rose Gold Plated and Sterling Silver Diamond Accent Wing Pendant with 18\" Chain: accessories\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6q9Eaf1zPTz",
        "colab_type": "text"
      },
      "source": [
        "The 'score' method computes the mean accuracy on the given test data and labels for the model we have trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJiid6SjiX7C",
        "colab_type": "code",
        "outputId": "e2eae4ac-d515-47cd-967a-e5b137213496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Finding the score of the model to see how accurate it is\n",
        "score = model.score(test_feature_set, y_test)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9512285467341647\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}